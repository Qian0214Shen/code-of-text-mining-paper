{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b256478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc6b1a",
   "metadata": {},
   "source": [
    "Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "dd=pd.DataFrame(df['text'].astype(str))\n",
    "words = []\n",
    "for i, row in dd.iterrows():\n",
    "    word = jieba.cut(row['text'])\n",
    "    result = ' '.join(word) \n",
    "    words.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ca9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(words)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f27112",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5338ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "pca.fit(X)\n",
    "X1=pca.transform(X)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X1\n",
    "y=df['score']\n",
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55355e9",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(random_state=933)\n",
    "X_n, y_n=smote.fit_resample(X,y)\n",
    "Counter(y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45957cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb040733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y_n, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "mode = XGBClassifier()\n",
    "model = mode.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1baa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96253ce7",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3634566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y, y_pred, title, labels):\n",
    "    fig, ax =plt.subplots(figsize=(7.5,7.5))\n",
    "    ax=sns.heatmap(confusion_matrix(y, y_pred), annot=True, cmap=\"Purples\", fmt='g', cbar=False, annot_kws={\"size\":30})\n",
    "    plt.title(title, fontsize=25)\n",
    "    ax.xaxis.set_ticklabels(labels, fontsize=16) \n",
    "    ax.yaxis.set_ticklabels(labels, fontsize=14.5)\n",
    "    ax.set_ylabel('Test', fontsize=25)\n",
    "    ax.set_xlabel('Predicted', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "sentiments = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "print('Classification Report for Naive Bayes:\\n',classification_report(y_test, y_pred, target_names=sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "conf_matrix(y_test,y_pred,'XGBoost after PCA and Oversampling\\nConfusion Matrix', sentiments)\n",
    "plt.savefig('D:/desktop/hxjzxgb.jpg',dpi=800,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dd4af",
   "metadata": {},
   "source": [
    "Multi-class ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "Y_test1 = label_binarize(y_test,classes=[1, 2, 3, 4, 5])\n",
    "n_classes = Y_test1.shape[1] \n",
    "Y_train1 = label_binarize(y_train, classes=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clt = OneVsRestClassifier(XGBClassifier(eval_metric=['logloss']))\n",
    "clf = clt.fit(X=X_train, y=Y_train1)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score = clf.predict_proba(X_test)\n",
    "# (1) For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test1[:, i],\n",
    "                                                        y_score[:, i])\n",
    "\n",
    "    average_precision[i] = average_precision_score(Y_test1[:, i], \n",
    "                                                   y_score[:, i])\n",
    "\n",
    "\n",
    "# (2) A \"macro-average\": quantifying score on all classes jointly\n",
    "precision[\"macro\"], recall[\"macro\"], _ = precision_recall_curve(Y_test1.ravel(),\n",
    "                                                                y_score.ravel())\n",
    "\n",
    "average_precision[\"macro\"] = average_precision_score(Y_test1, y_score,\n",
    "                                                     average=\"macro\")\n",
    "\n",
    "print('Average precision score, macro-averaged over all classes: {0:0.2f}'.format(average_precision[\"macro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.step(recall['macro'], precision['macro'], where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(Y_test1[:, i], y_score[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(Y_test1.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
